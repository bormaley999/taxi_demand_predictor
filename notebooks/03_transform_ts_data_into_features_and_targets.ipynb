{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Dictionary\n",
    "- `n_features` = number of hours per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/_3n7n2lx3xz5wzqkhfq69b0r0000gn/T/ipykernel_61306/268987735.py:8: UserWarning:Unsupported display type. Default display option should either be `lux` or `pandas`.\n",
      "/var/folders/8d/_3n7n2lx3xz5wzqkhfq69b0r0000gn/T/ipykernel_61306/268987735.py:9: UserWarning:Unsupported plotting backend. Lux currently only support 'altair', 'vegalite', or 'matplotlib'\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from src.libs import *\n",
    "\n",
    "# retina display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# lux-api details increase the size of the visualizations\n",
    "lux.config.default_display = \"lux-widget\"\n",
    "lux.config.plotting_backend = \"plotly\"\n",
    "lux.config.default_display_size = \"large\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e41144e4ee47d792dbf86ed2997691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbb4e7545db4725849bc9b89618dd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using option 1 dataset\n",
    "ts_data_option_1 = pd.read_parquet('../data/transformed/option_1_rides_per_hour_ts_2022_01.parquet')\n",
    "ts_data_option_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc6ccb1ce274bd89647b48c567ef5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e015428e5dd4629a58baa9c9d69b7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using Central Park location\n",
    "ts_data_one_location = ts_data_option_1.loc[ts_data_option_1.pickup_location_id == 43,:].reset_index(drop=True)\n",
    "ts_data_one_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create features and targets\n",
    "\n",
    "def get_cutoff_indices(\n",
    "        data: pd.DataFrame,\n",
    "        n_features: int, # hours\n",
    "        step_size: int,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    This function returns the indices of the cutoff date in the dataframe.\n",
    "\n",
    "    Input: pd.DataFrame, n_features(12 h for now), step_size (default 1 day,could be extended)\n",
    "    Output: list of indices\n",
    "    \"\"\"\n",
    "    # init\n",
    "    stop_position = len(data) - 1\n",
    "\n",
    "    # start the first sub-sequence at the beginning of the data\n",
    "    subseq_first_idx = 0\n",
    "    subseq_mid_idx = n_features\n",
    "    subseq_last_idx = n_features + 1\n",
    "    indices = []\n",
    "\n",
    "    # loop over the data\n",
    "    while subseq_last_idx <= stop_position:\n",
    "        # get the indices\n",
    "        indices.append((subseq_first_idx, subseq_mid_idx, subseq_last_idx))\n",
    "        \n",
    "        # update the indices\n",
    "        subseq_first_idx += step_size\n",
    "        subseq_mid_idx += step_size\n",
    "        subseq_last_idx += step_size\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the output\n",
    "n_features = 24 # 24 hours\n",
    "step_size = 1   # 1 day\n",
    "\n",
    "indices = get_cutoff_indices(ts_data_one_location, n_features, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 24, 25), (1, 25, 26), (2, 26, 27), (3, 27, 28), (4, 28, 29)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the slicing using the indices\n",
    "\n",
    "n_examples = len(indices)\n",
    "\n",
    "# shape is number of examples(len of the list), number of features (columns)\n",
    "X = np.ndarray(shape=(n_examples, n_features), dtype=np.float32)\n",
    "\n",
    "# 1D vector with number of rows = number of examples\n",
    "y = np.ndarray(shape=(n_examples), dtype=np.float32)\n",
    "pickup_hours = []\n",
    "\n",
    "# loop over the indices to generate the values for features and targets\n",
    "for i, idx in enumerate(indices):\n",
    "    # get the features\n",
    "    # extracting the first and the second index of the cutoff indices\n",
    "    X[i, :] = ts_data_one_location.iloc[idx[0]:idx[1]]['rides'].values\n",
    "\n",
    "    # get the target\n",
    "    # extracting the second and the third index of the cutoff indices (mid and right side ones)\n",
    "    y[i] = ts_data_one_location.iloc[idx[1]:idx[2]]['rides'].values\n",
    "\n",
    "    # store the pickup hours\n",
    "    pickup_hours.append(ts_data_one_location.iloc[idx[1]]['pickup_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (719, 24)\n",
      "y shape: (719,)\n",
      "X=array([[ 97.,  60.,  22., ...,  16.,  18.,   6.],\n",
      "       [ 60.,  22.,   8., ...,  18.,   6.,   3.],\n",
      "       [ 22.,   8.,   6., ...,   6.,   3.,   1.],\n",
      "       ...,\n",
      "       [ 28.,  16.,  13., ..., 102.,  66.,  61.],\n",
      "       [ 16.,  13.,   8., ...,  66.,  61.,  73.],\n",
      "       [ 13.,   8.,   1., ...,  61.,  73.,  33.]], dtype=float32)\n",
      "pickup hours: pickup_hours[:5]=[Timestamp('2022-01-02 00:00:00'), Timestamp('2022-01-02 01:00:00'), Timestamp('2022-01-02 02:00:00'), Timestamp('2022-01-02 03:00:00'), Timestamp('2022-01-02 04:00:00')]\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the features and targets\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n",
    "print(f'{X=}')\n",
    "print(f'pickup hours: {pickup_hours[:5]=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above should be the same is in the cell \"# using Central Park location\". See timestamps and their position within the output - they should match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34166591caf04ecdbea8e31d6fdec395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a246ccaed1fe42a69d9120d20b037afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert numpy arrays to pandas dataframes for X values\n",
    "ts_data_one_location = pd.DataFrame(\n",
    "    X, \n",
    "    columns=[f'rides_previous_{i+1}_hour' for i in reversed(range(n_features))])\n",
    "ts_data_one_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b79d230e21d40d2aa2ca9832dcb7b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655672f73766411cab4ca3f38494cadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transform the target into a dataframe\n",
    "targets_ts_data_one_location = pd.DataFrame(y, columns=[f'target_rides_next_hour'])\n",
    "targets_ts_data_one_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that transforms the entire dataset into features and targets for all locations\n",
    "\n",
    "def transform_ts_data_into_features_and_targets(\n",
    "        ts_data: pd.DataFrame,\n",
    "        input_seq_len: int, # number of features\n",
    "        step_size: int,\n",
    ") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        This function transforms the time series data into features and targets.\n",
    "        Slices and transposes datafrom time series to supervised learning problem(features and targets).\n",
    "        \"\"\"\n",
    "        assert set(ts_data.columns) == {\n",
    "                'pickup_location_id',\n",
    "                  'pickup_hour', \n",
    "                  'rides'},'The columns of the dataframe are not correct.'\n",
    "\n",
    "\n",
    "        # init\n",
    "        location_ids = ts_data.pickup_location_id.unique()\n",
    "        features = pd.DataFrame()\n",
    "        targets = pd.DataFrame()\n",
    "\n",
    "        # loop over the locations\n",
    "        for location_id in tqdm(location_ids):\n",
    "                # keep only ts data for this location id\n",
    "                ts_data_one_location = ts_data.loc[ts_data.pickup_location_id == location_id,\n",
    "                                                   ['pickup_hour', 'rides']]#.reset_index(drop=True)\n",
    "                # pre-compute cutoff indices to split dataframe rows\n",
    "                indices = get_cutoff_indices(ts_data_one_location, input_seq_len, step_size)\n",
    "\n",
    "                # slide and transpose the data into numpy arrays for features and targets\n",
    "                n_examples = len(indices)\n",
    "                X = np.ndarray(shape=(n_examples, input_seq_len), dtype=np.float32)\n",
    "                y = np.ndarray(shape=(n_examples), dtype=np.float32)\n",
    "                pickup_hours = []\n",
    "\n",
    "                # loop over the indices to generate the values for features and targets\n",
    "                for i, idx in enumerate(indices):\n",
    "                        # get the features\n",
    "                        # extracting the first and the second index of the cutoff indices\n",
    "                        X[i, :] = ts_data_one_location.iloc[idx[0]:idx[1]]['rides'].values\n",
    "\n",
    "                        # get the target\n",
    "                        # extracting the second and the third index of the cutoff indices (mid and right side ones)\n",
    "                        y[i] = ts_data_one_location.iloc[idx[1]:idx[2]]['rides'].values\n",
    "\n",
    "                        # store the pickup hours\n",
    "                        pickup_hours.append(ts_data_one_location.iloc[idx[1]]['pickup_hour'])\n",
    "\n",
    "                # numpy -> pandas for X\n",
    "                # convert numpy arrays to pandas dataframes for X values\n",
    "                ts_data_one_location = pd.DataFrame(\n",
    "                X, \n",
    "                columns=[f'rides_previous_{i+1}_hour' for i in reversed(range(input_seq_len))])\n",
    "                ts_data_one_location\n",
    "                \n",
    "                # numpy -> pandas for y\n",
    "                # transform the target into a dataframe\n",
    "                targets_ts_data_one_location = pd.DataFrame(y, columns=[f'target_rides_next_hour'])\n",
    "                targets_ts_data_one_location\n",
    "                \n",
    "                # concat the results from the previous iterations\n",
    "                features = pd.concat([features, ts_data_one_location], axis=0)\n",
    "                targets = pd.concat([targets, targets_ts_data_one_location], axis=0)\n",
    "                \n",
    "        # remove the index to make the output consistent\n",
    "        features.reset_index(drop=True, inplace=True)\n",
    "        targets.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return features, targets['target_rides_next_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:02<00:00, 115.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (6168, 168)\n",
      "targets shape: (6168,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calling the function\n",
    "features, targets = transform_ts_data_into_features_and_targets(\n",
    "    ts_data_option_1,\n",
    "    input_seq_len=24*7*1, # 1 week of history data\n",
    "    step_size=24, # 24 hours \\ 1 day\n",
    ")\n",
    "\n",
    "print(f'features shape: {features.shape}')\n",
    "print(f'targets shape: {targets.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parallelize the function transform_ts_data_into_features_and_targets\n",
    "# # using joblib\n",
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
